CORES.C(1)            User Contributed Perl Documentation           CORES.C(1)



NNAAMMEE
       src/runcore/cores.c - Parrot's execution runcores

DDEESSCCRRIIPPTTIIOONN
       During execution, the runcore is like the heart of Parrot. The runcore
       controls calling the various opcodes with the correct data, and making
       sure that program flow moves properly. Some runcores, such as the
       _p_r_e_c_o_m_p_u_t_e_d _C _g_o_t_o _r_u_n_c_o_r_e are optimized for speed and don't perform
       many tasks beyond finding and dispatching opcodes. Other runcores, such
       as the _G_C_-_D_e_b_u_g, _d_e_b_u_g and _p_r_o_f_i_l_i_n_g runcores help with typical
       software maintenance and analysis tasks. We'll talk about all of these
       throughout the chapter.

       Runcores must pass execution to each opcode in the incoming bytecode
       stream. This is called _d_i_s_p_a_t_c_h_i_n_g the opcodes. Because the different
       runcores are structured in different ways, the opcodes themselves must
       be formated differently. The opcode compiler compiles opcodes into a
       number of separate formats, depending on what runcores are included in
       the compiled Parrot. Because of this, understanding opcodes first
       requires an understanding of the Parrot runcores.

       Parrot has multiple runcores. Some are useful for particular
       maintenance tasks, some are only available as optimizations in certain
       compilers, some are intended for general use, and some are just
       interesting flights of fancy with no practical benefits. Here we list
       the various runcores, their uses, and their benefits.

   SSllooww CCoorree
       The slow core is a basic runcore design that treats each opcode as a
       separate function at the C level. Each function is called, and returns
       the address of the next opcode to be called by the core. The slow core
       performs bounds checking to ensure that the next opcode to be called is
       properly in bounds, and not somewhere random in memory. Because of this
       modular approach where opcodes are treated as separate executable
       entities many other runcores, especially diagnostic and maintenance
       cores are based on this design. The program counter "pc" is the current
       index into the bytecode stream. Here is a pseudocode representation for
       how the slow core works:

         while(1) {
             pc = NEXT_OPCODE;
             if(pc < LOW_BOUND || pc > HIGH_BOUND)
                 throw exception;
             DISPATCH_OPCODE(pc);
             UPDATE_INTERPRETER();
         }

   FFaasstt CCoorree
       The fast core is a bare-bones core that doesn't do any of the bounds-
       checking or context updating that the slow core does. The fast core is
       the way Parrot should run, and is used to find and debug places where
       execution strays outside of its normal bounds. In pseudocode, the fast
       core is very much like the slow core except it doesn't do the bounds
       checking between each instruction, and doesn't update the interpreter's
       current context for each dispatch.

         while(1) {
             pc = NEXT_OPCODE;
             DISPATCH_OPCODE(pc);
         }

   SSwwiittcchh CCoorree
       As its name implies, the switch core uses a gigantic C "switch / case"
       structure to execute opcodes. Here's a brief example of how this
       architecture works:

         for( ; ; ++current_opcode) {
             switch(*current_opcode) {
                 case opcode_1:
                     ...
                 case opcode_2:
                     ...
                 case opcode_3:
                     ...
             }
         }

       This is quite a fast architecture for dispatching opcodes because it
       all happens within a single function. The only operations performed
       between opcodes is a jump back to the top of the loop, incrementing the
       opcode pointer, dereferencing the opcode pointer, and then a jump to
       the "case" statement for the next opcode.

   CCoommppuutteedd GGoottoo CCoorree
       _C_o_m_p_u_t_e_d _G_o_t_o is a feature of some C compilers where a label is treated
       as a piece of data that can be stored as a "void *" pointer. Each
       opcode becomes simply a label in a very large function, and pointers to
       the labels are stored in a large array. Calling an opcode is as easy as
       taking that opcode's number as the index of the label array, and
       calling the associated label. Sound complicated? It is a little,
       especially to C programmers who are not used to using labels, much less
       treating them as first class data items.

       Notice that computed goto is a feature only available in some compilers
       such as GCC, and will not be available in every distribution of Parrot,
       depending what compilers were used to build it.

       As was mentioned earlier, not all compilers support computed goto,
       which means that this core will not be built on platforms that don't
       support it.  However, it's still an interesting topic to study so we
       will look at it briefly here. For compilers that support it, computed
       goto labels are "void **" values. In the computed goto core, all the
       labels represent different opcodes, so they are stored in an array:

         void *my_labels[] = {
             &&label1,
             &&label2,
             &&label3
         };

         label1:
             ...
         label2:
             ...
         label3:
             ...

       Jumping to one of these labels is done with a command like this:

         goto *my_labels[opcode_number];

       Actually, opcodes are pointed to by an "opcode_t *" pointer, and all
       opcodes are stored sequentially in memory, so the actual jump in the
       computed goto core must increment the pointer and then jump to the new
       version. In C it looks something like this:

         goto *my_labels[*(current_opcode += 1)];

       Each opcode is an index into the array of labels, and at the end of
       each opcode an instruction like this is performed to move to the next
       opcode in series, or else some kind of control flow occurs that moves
       it to a non-sequential location:

         goto *my_lables[*(current_opcode = destination)];

       These are simplifications on what really happens in this core, because
       the actual code has been optimized quite a bit from what has been
       presented here. However, as we shall see with the precomputed goto
       core, it isn't optimized as aggressively as is possible.

   PPrreeccoommppuutteedd GGoottoo CCoorree
       The precomputed goto core is an amazingly fast optimized core that uses
       the same computed goto feature, but performs the array dereferencing
       before the core even starts. The compiled bytecode is fed into a
       preprocessor that converts the bytecode instruction numbers into label
       pointer values. In the computed goto core, you have this operation to
       move to the next opcode:

         goto *my_labels[*(current_opcode += 1)];

       This single line of code is deceptively complex. A number of machine
       code operations must be performed to complete this step: The value of
       "current_opcode" must be incremented to the next value, that value must
       be dereferenced to find the opcode value. In C, arrays are pointers, so
       "my_labels" gets dereferenced and an offset is taken from it to find
       the stored label reference. That label reference is then dereferenced,
       and the jump is performed.

       That's a lot of steps to execute before we can jump to the next opcode.
       What if each opcode value was replaced with the value of the jump label
       beforehand? If "current_opcode" points to a label pointer directly, we
       don't need to perform an additional dereference on the array at all. We
       can replace that entire mess above with this line:

         goto **(current_opcode += 1);

       That's far fewer machine instructions to execute before we can move to
       the next opcode, which means faster throughput. Remember that whatever
       dispatch mechanism is used will be called after every single opcode,
       and some large programs may have millions of opcodes! Every single
       machine instruction that can be cut out of the dispatch mechanism could
       increase the execution speed of Parrot in a significant and noticeable
       way. TThhee ddiissppaattcchh mmeecchhaanniissmm uusseedd bbyy tthhee vvaarriioouuss rruunnccoorreess iiss hhaarrddllyy tthhee
       llaarrggeesstt ppeerrffoorrmmaannccee bboottttlleenneecckk iinn PPaarrrroott aannyywwaayy,, bbuutt wwee lliikkee ttoo uussee
       ffaasstteerr ccoorreess ttoo sshhaavvee eevveerryy lliittttllee bbiitt ooff ssppeeeedd oouutt ooff tthhee ssyysstteemm.

       The caveat of course is that the predereferenced computed goto core is
       only available with compilers that support computed goto, such as GCC.
       Parrot will not have access to this core if it is built with a
       different compiler.

   TTrraacciinngg CCoorree
       To come.

   PPrrooffiilliinngg CCoorree
       The profiling core analyzes the performance of Parrot, and helps to
       determine where bottlenecks and trouble spots are in the programs that
       run on top of Parrot. When Parrot calls a PIR subroutine it sets up the
       environment, allocates storage for the passed parameters and the return
       values, passes the parameters, and calls a new runcore to execute it.
       To calculate the amount of time that each subroutine takes, we need to
       measure the amount of time spent in each runcore from the time the core
       begins to the time the core executes. The profiling core does exactly
       this, acting very similarly to a slow core but also measuring the
       amount of time it takes for the core to complete. The tracing core
       actually keeps track of a few additional values, including the number
       of GC cycles run while in the subroutine, the number of each opcode
       called and the number of calls to each subroutine made. All this
       information is helpfully printed to the STDERR output for later
       analysis.

   GGCC DDeebbuugg CCoorree
       Parrot's garbage collector has been known as a weakness in the system
       for several years. In fact, the garbage collector and memory management
       subsystem was one of the last systems to be improved and rewritten
       before the release of version 1.0. It's not that garbage collection
       isn't important, but instead that it was so hard to do earlier in the
       project.

       Early on when the GC was such a weakness, and later when the GC was
       under active development, it was useful to have an operational mode
       that would really exercise the GC and find bugs that otherwise could
       hide by sheer chance. The GC debug runcore was this tool. The core
       executes a complete collection iteration between every single opcode.
       The throughput performance is terrible, but that's not the point: it's
       almost guaranteed to find problems in the memory system if they exist.

   DDeebbuugg CCoorree
       The debug core works like a normal software debugger, such as GDB. The
       debug core executes each opcode, and then prompts the user to enter a
       command. These commands can be used to continue execution, step to the
       next opcode, or examine and manipulate data from the executing program.

   FFuunnccttiioonnss
       "void Parrot_runcore_slow_init(PARROT_INTERP)"
           Registers the slow runcore with Parrot.

       "void Parrot_runcore_fast_init(PARROT_INTERP)"
           Registers the fast runcore with Parrot.

       "void Parrot_runcore_exec_init(PARROT_INTERP)"
           Registers the exec runcore with Parrot.

       "void Parrot_runcore_gc_debug_init(PARROT_INTERP)"
           Registers the gc_debug runcore with Parrot.

       "void Parrot_runcore_debugger_init(PARROT_INTERP)"
           Registers the debugger runcore with Parrot.

       "static opcode_t * runops_fast_core(PARROT_INTERP, Parrot_runcore_t
       *runcore, opcode_t *pc)"
           Runs the Parrot operations starting at "pc" until there are no more
           operations.  This performs no bounds checking, profiling, or
           tracing.

       "static opcode_t * runops_trace_core(PARROT_INTERP, opcode_t *pc)"
           Runs the Parrot operations starting at "pc" until there are no more
           operations, using the tracing interpreter.

       "static opcode_t * runops_slow_core(PARROT_INTERP, Parrot_runcore_t
       *runcore, opcode_t *pc)"
           Runs the Parrot operations starting at "pc" until there are no more
           operations, with tracing and bounds checking enabled.

       "static opcode_t * runops_gc_debug_core(PARROT_INTERP, Parrot_runcore_t
       *runcore, opcode_t *pc)"
           Runs the Parrot operations starting at "pc" until there are no more
           operations, performing a full GC run before each op.  This is very
           slow, but it's also a very quick way to find GC problems.

       "static opcode_t * runops_debugger_core(PARROT_INTERP, Parrot_runcore_t
       *runcore, opcode_t *pc)"
           Used by the debugger, under construction

       "oplib_init_f get_core_op_lib_init(PARROT_INTERP, Parrot_runcore_t
       *runcore)"
           Returns an opcode's library "op_lib" init function.

       "static opcode_t * runops_exec_core(PARROT_INTERP, Parrot_runcore_t
       *runcore, opcode_t *pc)"
           Runs the native executable version of the specified opcode.



perl v5.12.3                      2011-11-10                        CORES.C(1)
